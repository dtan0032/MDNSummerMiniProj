{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Miniproject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQGvL-w0Rp5I"
      },
      "source": [
        "# Imports\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Dfirj7RM86"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "from torch import optim\r\n",
        "from torchvision import datasets, transforms, models\r\n",
        "\r\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JJ9rd9KS8E3"
      },
      "source": [
        "#Dataset\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b8DiOvATKYr"
      },
      "source": [
        "Dataset from https://www.kaggle.com/puneet6060/intel-image-classification.\r\n",
        "\r\n",
        "Guide to downloading Kaggle dataset directly into colab: https://www.kaggle.com/general/74235."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6NTLd2tkc4Pa",
        "outputId": "f0cd57ff-4731-40d9-92fe-d4e12956d86c"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9eoJew4c4HO"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUX68rhEc3zC"
      },
      "source": [
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTN_g_WpdbWr"
      },
      "source": [
        "!kaggle datasets download -d puneet6060/intel-image-classification "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-3zza3JdbPr"
      },
      "source": [
        "import zipfile\r\n",
        "zip_ref = zipfile.ZipFile('intel-image-classification.zip', 'r')\r\n",
        "zip_ref.extractall('files')\r\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUuYBH01TG89"
      },
      "source": [
        "training_transforms = transforms.Compose([transforms.RandomRotation(30),\r\n",
        "                                          transforms.RandomHorizontalFlip(),\r\n",
        "                                          transforms.RandomResizedCrop(128),\r\n",
        "                                          transforms.ToTensor(),\r\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406], \r\n",
        "                                                               [0.229, 0.224, 0.225])\r\n",
        "                                          ])\r\n",
        "\r\n",
        "validation_transforms = transforms.Compose([\r\n",
        "                                            transforms.RandomResizedCrop(128),\r\n",
        "                                            transforms.ToTensor(),\r\n",
        "                                            transforms.Normalize([0.485, 0.456, 0.406], \r\n",
        "                                                                 [0.229, 0.224, 0.225])\r\n",
        "                                            ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIw8njSJsWXU"
      },
      "source": [
        "train_path = '/content/files/seg_train/seg_train'\r\n",
        "valid_path = '/content/files/seg_train/seg_test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmViW-mlTTNy"
      },
      "source": [
        "training_dataset = datasets.ImageFolder(train_path, transform = training_transforms )\r\n",
        "validation_dataset = datasets.ImageFolder(train_path, transform = validation_transforms )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LwYv2w5TTGP"
      },
      "source": [
        "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True)\r\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=32, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyPwRdepTS3D"
      },
      "source": [
        "training_dataset.classes, validation_dataset.classes\r\n",
        "\r\n",
        "num_classes = len(validation_dataset.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDskHohx_STU"
      },
      "source": [
        "There are 6 classes\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "symldHqGSmlH"
      },
      "source": [
        "#Create Model\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLUYFUhF_kD4"
      },
      "source": [
        "Input image shape is 150*150 pixels with 3 RGB channels. \r\n",
        "\r\n",
        "###Notes:\r\n",
        "All layers are found in nn:\r\n",
        "* Fully Connected Layer: `Linear(num inputs, num outputs)`\r\n",
        "* Max Pooling: `MaxPool2d(kernel size, stride)`\r\n",
        "* Convolutional Layer: `Conv2d(input channels, output channels, kernel size, stride)`\r\n",
        "* Define your layers in the `__init__` method of your model\r\n",
        "* Flatten a PyTorch tensor using `.flatten()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22jtIWOSSka4"
      },
      "source": [
        "class MyModel(nn.Module):\r\n",
        "  def __init__(self, num_classes):\r\n",
        "      super(MyModel,self).__init__()\r\n",
        "      self.convo1 = nn.Conv2d(in_channels = 3,out_channels = 7,kernel_size= 5,stride = 1)\r\n",
        "      self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\r\n",
        "      self.convo2 = nn.Conv2d(in_channels = 7,out_channels = 14,kernel_size= 5,stride = 1)\r\n",
        "      self.fc1 = nn.Linear(in_features=11774,out_features=64) \r\n",
        "      self.fc2 = nn.Linear(in_features=64, out_features=num_classes)\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "      x = self.convo1(x)\r\n",
        "      x = torch.nn.functional.relu(x)\r\n",
        "      x = self.pool(x)\r\n",
        "      x = self.convo2(x)\r\n",
        "      x = torch.nn.functional.relu(x)\r\n",
        "      x = self.pool(x)\r\n",
        "      x = torch.flatten(x, start_dim=1)\r\n",
        "      x = self.fc1(x)\r\n",
        "      x = torch.nn.functional.relu(x)\r\n",
        "\r\n",
        "      x = self.fc2(x)\r\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkf5_X0Z_zfJ"
      },
      "source": [
        "#Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzuhPKrCt8S6"
      },
      "source": [
        "# Function for the training \r\n",
        "\r\n",
        "def train(model, train_loader, loss_fn, optimizer, device):\r\n",
        "    model.train() # puts the model in training mode\r\n",
        "    running_loss = 0\r\n",
        "    with tqdm(total=len(train_loader)) as pbar:\r\n",
        "        for i, data in enumerate(train_loader, 0): # loops through training data\r\n",
        "            inputs, labels = data # separate inputs and labels (outputs)\r\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # puts the data on the GPU\r\n",
        "\r\n",
        "            # forward + backward + optimize                                          \r\n",
        "            optimizer.zero_grad() # clear the gradients in model parameters\r\n",
        "            outputs = model(inputs) # forward pass and get predictions\r\n",
        "            loss = loss_fn(outputs, labels) # calculate loss\r\n",
        "            loss.backward() # calculates gradient w.r.t to loss for all parameters in model that have requires_grad=True\r\n",
        "            optimizer.step() # iterate over all parameters in the model with requires_grad=True and update their weights.\r\n",
        "\r\n",
        "            running_loss += loss.item() # sum total loss in current epoch for print later\r\n",
        "\r\n",
        "            pbar.update(1) #increment our progress bar\r\n",
        "\r\n",
        "    return running_loss/len(train_loader) # returns the total training loss for the epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75kIlOqS_-vi"
      },
      "source": [
        "# Function for the validation pass\r\n",
        "\r\n",
        "def validation(model, val_loader, loss_fn, device):\r\n",
        "    model.eval() # puts the model in validation mode\r\n",
        "    running_loss = 0\r\n",
        "    total = 0\r\n",
        "    correct = 0\r\n",
        "    \r\n",
        "    with torch.no_grad(): # save memory by not saving gradients which we don't need \r\n",
        "        with tqdm(total=len(val_loader)) as pbar:\r\n",
        "            for images, labels in iter(val_loader):\r\n",
        "                images, labels = images.to(device), labels.to(device) # put the data on the GPU\r\n",
        "                outputs = model(images) # passes image to the model, and gets a ouput which is the class probability prediction\r\n",
        "\r\n",
        "                val_loss = loss_fn(outputs, labels) # calculates val_loss from model predictions and true labels\r\n",
        "                running_loss += val_loss.item()\r\n",
        "                _, predicted = torch.max(outputs, 1) # turns class probability predictions to class labels\r\n",
        "                total += labels.size(0) # sums the number of predictions\r\n",
        "                correct += (predicted == labels).sum().item() # sums the number of correct predictions\r\n",
        "        \r\n",
        "                pbar.update(1)\r\n",
        "\r\n",
        "        return running_loss/len(val_loader), correct/total # return loss value, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gASBqINyAFVP"
      },
      "source": [
        "#Model Instantiation\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbrVeyKqADIo"
      },
      "source": [
        "model = MyModel(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFnAKWqAJZx"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Determine whether a GPU is available\r\n",
        "model.to(device) # send model to GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXGILKyuANTc"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss() # We use Cross Entropy Loss, as this is a classification task\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001) # If in doubt, we use Adam as our optimiser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cblZU7b2ARMz"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyGW_C5gAU5X"
      },
      "source": [
        "total_epoch = 20 # Define how many epochs of training we want\r\n",
        "\r\n",
        "# keep track of things we'd like to plot later\r\n",
        "training_losses = []\r\n",
        "validation_losses = []\r\n",
        "accuracies = []\r\n",
        "\r\n",
        "for epoch in range(total_epoch): # loops through number of epochs\r\n",
        "  train_loss = train(model, training_loader, loss_fn, optimizer, device)  # train the model for one epoch\r\n",
        "  val_loss, accuracy = validation(model, validation_loader, loss_fn, device) # after training for one epoch, run the validation() function to see how the model is doing on the validation dataset\r\n",
        "  \r\n",
        "  # keep track of interesting stuff\r\n",
        "  training_losses.append(train_loss)\r\n",
        "  validation_losses.append(val_loss)\r\n",
        "  accuracies.append(accuracy)\r\n",
        "  \r\n",
        "  print(\"Epoch: {}/{}, Training Loss: {}, Val Loss: {}, Val Accuracy: {}\".format(epoch+1, total_epoch, train_loss, val_loss, accuracy))\r\n",
        "  print('-' * 20)\r\n",
        "\r\n",
        "print(\"Finished Training\")\r\n",
        "\r\n",
        "# Save the queen\r\n",
        "torch.save(model.state_dict(), 'finished')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-99O6JEAZKK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}